{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# # AI Model for Detecting Python Learning Preferences\n",
    "# \n",
    "# This notebook trains a Random Forest classifier to detect whether users are looking to learn Python based on their queries and code examples.\n"
   ],
   "id": "7ce7a28090a01efc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# ## 1. Import Required Libraries\n",
   "id": "7fc6f2b6aa74867f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n"
   ],
   "id": "b471d79ad5ac59dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# ## 2. Load and Explore the Dataset\n",
   "id": "5baf8ea019646112"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('DataSet/student+performance/student/Python codes.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n"
   ],
   "id": "d77389346bc99e85"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# ## 3. Data Preprocessing\n",
   "id": "57b8d678495e6958"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create a copy for preprocessing\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Feature engineering: Create features based on question content\n",
    "def extract_features(text):\n",
    "    \"\"\"Extract features from question text\"\"\"\n",
    "    features = {}\n",
    "\n",
    "    # Convert to string\n",
    "    text = str(text).lower()\n",
    "\n",
    "    # Length features\n",
    "    features['text_length'] = len(text)\n",
    "    features['word_count'] = len(text.split())\n",
    "\n",
    "    # Content features\n",
    "    features['contains_python'] = int('python' in text)\n",
    "    features['contains_learn'] = int(any(word in text for word in ['learn', 'study', 'teach', 'tutorial']))\n",
    "    features['contains_code'] = int(any(word in text for word in ['code', 'program', 'function', 'script']))\n",
    "    features['contains_example'] = int(any(word in text for word in ['example', 'sample', 'demonstrate']))\n",
    "    features['contains_question'] = int('?' in text)\n",
    "\n",
    "    # Programming concepts\n",
    "    features['contains_loop'] = int(any(word in text for word in ['loop', 'for', 'while', 'iterate']))\n",
    "    features['contains_function'] = int(any(word in text for word in ['function', 'def ', 'method']))\n",
    "    features['contains_class'] = int(any(word in text for word in ['class', 'object', 'oop']))\n",
    "    features['contains_array'] = int(any(word in text for word in ['array', 'list', '[]']))\n",
    "    features['contains_string'] = int(any(word in text for word in ['string', 'str ', 'text']))\n",
    "\n",
    "    # Difficulty indicators\n",
    "    features['contains_basic'] = int(any(word in text for word in ['basic', 'simple', 'easy', 'beginner']))\n",
    "    features['contains_advanced'] = int(any(word in text for word in ['advanced', 'complex', 'difficult', 'expert']))\n",
    "\n",
    "    return features\n",
    "\n",
    "# Extract features from questions\n",
    "feature_columns = []\n",
    "for idx, row in df_processed.iterrows():\n",
    "    features = extract_features(row['question'])\n",
    "    for key, value in features.items():\n",
    "        df_processed.loc[idx, key] = value\n",
    "        if key not in feature_columns:\n",
    "            feature_columns.append(key)\n",
    "\n",
    "# Analyze code complexity\n",
    "def analyze_code_complexity(code):\n",
    "    \"\"\"Analyze code complexity features\"\"\"\n",
    "    code = str(code)\n",
    "    features = {}\n",
    "\n",
    "    features['code_length'] = len(code)\n",
    "    features['code_lines'] = code.count('\\n') + 1\n",
    "    features['has_function'] = int('def ' in code.lower())\n",
    "    features['has_class'] = int('class ' in code.lower())\n",
    "    features['has_import'] = int('import ' in code.lower())\n",
    "    features['has_loop'] = int(any(word in code.lower() for word in ['for ', 'while ', 'range(']))\n",
    "    features['has_conditional'] = int(any(word in code.lower() for word in ['if ', 'elif ', 'else:', 'switch', 'case']))\n",
    "\n",
    "    return features\n",
    "\n",
    "# Extract code features\n",
    "code_feature_columns = []\n",
    "for idx, row in df_processed.iterrows():\n",
    "    features = analyze_code_complexity(row['code'])\n",
    "    for key, value in features.items():\n",
    "        df_processed.loc[idx, f'code_{key}'] = value\n",
    "        if f'code_{key}' not in code_feature_columns:\n",
    "            code_feature_columns.append(f'code_{key}')\n",
    "\n",
    "# Combine all feature columns\n",
    "all_feature_columns = feature_columns + code_feature_columns\n",
    "\n",
    "print(f\"Total features created: {len(all_feature_columns)}\")\n",
    "print(\"Feature columns:\", all_feature_columns)\n"
   ],
   "id": "7b98b1cb8b2f496d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# ## 4. Create Target Variable (Learning Preference)\n",
   "id": "1f51e1808ec6242e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define rules for labeling Python learning preferences\n",
    "def is_python_learning_query(text, code):\n",
    "    \"\"\"Determine if the query indicates Python learning preference\"\"\"\n",
    "    text = str(text).lower()\n",
    "    code = str(code).lower()\n",
    "\n",
    "    # Keywords indicating learning intent\n",
    "    learning_keywords = [\n",
    "        'learn python', 'python tutorial', 'python example',\n",
    "        'how to', 'what is', 'explain', 'understand',\n",
    "        'beginner', 'starting', 'getting started',\n",
    "        'teach me', 'show me', 'demonstrate'\n",
    "    ]\n",
    "\n",
    "    # Check for learning intent in text\n",
    "    for keyword in learning_keywords:\n",
    "        if keyword in text:\n",
    "            return 1\n",
    "\n",
    "    # Check for educational patterns in code\n",
    "    if ('# example' in code or '# sample' in code or\n",
    "        '# tutorial' in code or 'print(' in code):\n",
    "        return 1\n",
    "\n",
    "    # Check for basic programming concepts (often indicative of learning)\n",
    "    basic_concepts = ['for i in range', 'def ', 'if __name__', 'import ']\n",
    "    for concept in basic_concepts:\n",
    "        if concept in code and len(code) < 500:  # Shorter code often indicates learning examples\n",
    "            return 1\n",
    "\n",
    "    return 0\n",
    "\n",
    "# Apply labeling\n",
    "df_processed['is_learning_python'] = df_processed.apply(\n",
    "    lambda row: is_python_learning_query(row['question'], row['code']), axis=1\n",
    ")\n",
    "\n",
    "# Analyze label distribution\n",
    "learning_count = df_processed['is_learning_python'].sum()\n",
    "total_count = len(df_processed)\n",
    "learning_percentage = (learning_count / total_count) * 100\n",
    "\n",
    "print(f\"Learning Python examples: {learning_count}/{total_count} ({learning_percentage:.2f}%)\")\n",
    "print(\"\\nLabel Distribution:\")\n",
    "print(df_processed['is_learning_python'].value_counts())\n"
   ],
   "id": "b74536e3154f8fb9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# ## 5. Feature Analysis and Visualization\n",
   "id": "f331ee8465d862ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Visualize feature distributions\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Select key features for visualization\n",
    "key_features = [\n",
    "    'contains_python', 'contains_learn', 'contains_code',\n",
    "    'contains_example', 'contains_loop', 'contains_function',\n",
    "    'contains_basic', 'code_has_function', 'code_has_loop'\n",
    "]\n",
    "\n",
    "for i, feature in enumerate(key_features[:9]):\n",
    "    ax = axes[i]\n",
    "    df_processed.groupby('is_learning_python')[feature].mean().plot(kind='bar', ax=ax)\n",
    "    ax.set_title(f'{feature} by Learning Preference')\n",
    "    ax.set_xlabel('Is Learning Python')\n",
    "    ax.set_ylabel('Average Value')\n",
    "    ax.set_xticklabels(['No', 'Yes'], rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "547ead6dd91a713d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# ## 6. Prepare Data for Machine Learning\n",
   "id": "8734d9bd85035dae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Prepare features and target\n",
    "X = df_processed[all_feature_columns]\n",
    "y = df_processed['is_learning_python']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Testing set size: {X_test.shape}\")\n",
    "print(f\"\\nTraining class distribution:\\n{y_train.value_counts(normalize=True)}\")\n",
    "print(f\"\\nTesting class distribution:\\n{y_test.value_counts(normalize=True)}\")\n"
   ],
   "id": "2fc93f6ac2e8c38d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# ## 7. Train Random Forest Classifier\n",
   "id": "6fcdb5d2824be9a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize and train the model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "print(f\"\\nClassification Report:\\n{classification_report(y_test, y_pred)}\")\n"
   ],
   "id": "83ae1a207dd05a5c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# ## 8. Model Evaluation and Visualization\n",
   "id": "3b22567aa0888c56"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=rf_model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Not Learning', 'Learning'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Feature Importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': all_feature_columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=feature_importance.head(15), x='importance', y='feature')\n",
    "plt.title('Top 15 Feature Importances')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Learning Curve\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    rf_model, X, y, cv=5, n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10)\n",
    ")\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_scores_mean, label='Training score')\n",
    "plt.plot(train_sizes, test_scores_mean, label='Cross-validation score')\n",
    "plt.xlabel('Training Size')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "f109464d18fcd409"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# ## 9. Create Text-Based Features and Alternative Model\n",
   "id": "c01c972fc9dfb270"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create text-based features using TF-IDF\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=50,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "# Combine question and code for text analysis\n",
    "text_data = df_processed['question'].astype(str) + \" \" + df_processed['code'].astype(str)\n",
    "X_text = vectorizer.fit_transform(text_data)\n",
    "\n",
    "# Split text data\n",
    "X_text_train, X_text_test, y_text_train, y_text_test = train_test_split(\n",
    "    X_text, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train text-based model\n",
    "rf_text_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "rf_text_model.fit(X_text_train, y_text_train)\n",
    "\n",
    "# Evaluate text model\n",
    "y_text_pred = rf_text_model.predict(X_text_test)\n",
    "text_accuracy = accuracy_score(y_text_test, y_text_pred)\n",
    "\n",
    "print(f\"Text Model Accuracy: {text_accuracy:.4f}\")\n",
    "print(f\"\\nText Model Classification Report:\\n{classification_report(y_text_test, y_text_pred)}\")\n"
   ],
   "id": "418e2e5da21e5af5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# ## 10. Save the Models and Vectorizer\n",
   "id": "63fc35bb35784b43"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save the main model\n",
    "joblib.dump(rf_model, 'python_learning_detector_rf.pkl')\n",
    "\n",
    "# Save the text-based model\n",
    "joblib.dump(rf_text_model, 'python_learning_detector_text_rf.pkl')\n",
    "\n",
    "# Save the vectorizer\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
    "\n",
    "# Save feature names\n",
    "with open('feature_names.txt', 'w') as f:\n",
    "    for feature in all_feature_columns:\n",
    "        f.write(f\"{feature}\\n\")\n",
    "\n",
    "print(\"Models and artifacts saved successfully!\")\n"
   ],
   "id": "63888aa79793cd83"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# ## 11. Create Prediction Function\n",
   "id": "b379a9cf3bd53757"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def predict_python_learning(query, code_snippet=None):\n",
    "    \"\"\"\n",
    "    Predict if a query indicates Python learning preference\n",
    "\n",
    "    Parameters:\n",
    "    query (str): User's question or query\n",
    "    code_snippet (str): Associated code (optional)\n",
    "\n",
    "    Returns:\n",
    "    dict: Prediction results with confidence\n",
    "    \"\"\"\n",
    "    if code_snippet is None:\n",
    "        code_snippet = \"\"\n",
    "\n",
    "    # Extract features from query\n",
    "    features = extract_features(query)\n",
    "    code_features = analyze_code_complexity(code_snippet)\n",
    "\n",
    "    # Create feature vector\n",
    "    feature_vector = []\n",
    "    for col in all_feature_columns:\n",
    "        if col in features:\n",
    "            feature_vector.append(features[col])\n",
    "        elif f\"code_{col.replace('code_', '')}\" in code_features:\n",
    "            feature_vector.append(code_features[col.replace('code_', '')])\n",
    "        else:\n",
    "            feature_vector.append(0)\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = rf_model.predict([feature_vector])[0]\n",
    "    probability = rf_model.predict_proba([feature_vector])[0][1]\n",
    "\n",
    "    # Text-based prediction\n",
    "    text_input = query + \" \" + code_snippet\n",
    "    text_vector = vectorizer.transform([text_input])\n",
    "    text_prediction = rf_text_model.predict(text_vector)[0]\n",
    "    text_probability = rf_text_model.predict_proba(text_vector)[0][1]\n",
    "\n",
    "    # Combine predictions (weighted average)\n",
    "    combined_probability = (probability * 0.6) + (text_probability * 0.4)\n",
    "    final_prediction = 1 if combined_probability > 0.5 else 0\n",
    "\n",
    "    # Determine confidence level\n",
    "    if combined_probability > 0.8:\n",
    "        confidence = \"High\"\n",
    "    elif combined_probability > 0.6:\n",
    "        confidence = \"Medium\"\n",
    "    else:\n",
    "        confidence = \"Low\"\n",
    "\n",
    "    # Extract key learning indicators\n",
    "    learning_indicators = []\n",
    "    if features.get('contains_learn', 0):\n",
    "        learning_indicators.append(\"Contains learning keywords\")\n",
    "    if features.get('contains_python', 0):\n",
    "        learning_indicators.append(\"Mentions Python\")\n",
    "    if features.get('contains_basic', 0):\n",
    "        learning_indicators.append(\"Beginners/ Basic level\")\n",
    "    if features.get('contains_example', 0):\n",
    "        learning_indicators.append(\"Seeks examples\")\n",
    "\n",
    "    return {\n",
    "        'prediction': final_prediction,\n",
    "        'prediction_label': 'Learning Python' if final_prediction == 1 else 'Not Learning Python',\n",
    "        'confidence': confidence,\n",
    "        'probability': float(combined_probability),\n",
    "        'feature_based_probability': float(probability),\n",
    "        'text_based_probability': float(text_probability),\n",
    "        'learning_indicators': learning_indicators,\n",
    "        'key_features': {k: v for k, v in features.items() if v == 1}\n",
    "    }\n"
   ],
   "id": "ac18a11ac501ef95"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# ## 12. Test the Model with Examples\n",
   "id": "10acfb857c173eb1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def predict_python_learning(query, code_snippet=None):\n",
    "    \"\"\"\n",
    "    Predict if a query indicates Python learning preference\n",
    "\n",
    "    Parameters:\n",
    "    query (str): User's question or query\n",
    "    code_snippet (str): Associated code (optional)\n",
    "\n",
    "    Returns:\n",
    "    dict: Prediction results with confidence\n",
    "    \"\"\"\n",
    "    if code_snippet is None:\n",
    "        code_snippet = \"\"\n",
    "\n",
    "    # Extract features from query\n",
    "    features = extract_features(query)\n",
    "    code_features = analyze_code_complexity(code_snippet)\n",
    "\n",
    "    # Create feature vector in correct order\n",
    "    feature_vector = []\n",
    "    for col in all_feature_columns:\n",
    "        if col in features:\n",
    "            feature_vector.append(features[col])\n",
    "        elif col.startswith('code_'):\n",
    "            # Remove 'code_' prefix to match code_features keys\n",
    "            code_key = col.replace('code_', '')\n",
    "            feature_vector.append(code_features.get(code_key, 0))\n",
    "        else:\n",
    "            feature_vector.append(0)\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = rf_model.predict([feature_vector])[0]\n",
    "    probability = rf_model.predict_proba([feature_vector])[0][1]\n",
    "\n",
    "    # Text-based prediction\n",
    "    text_input = query + \" \" + code_snippet\n",
    "    text_vector = vectorizer.transform([text_input])\n",
    "    text_prediction = rf_text_model.predict(text_vector)[0]\n",
    "    text_probability = rf_text_model.predict_proba(text_vector)[0][1]\n",
    "\n",
    "    # Combine predictions\n",
    "    combined_probability = (probability * 0.6) + (text_probability * 0.4)\n",
    "    final_prediction = 1 if combined_probability > 0.5 else 0\n",
    "\n",
    "    # Confidence level\n",
    "    if combined_probability > 0.8:\n",
    "        confidence = \"High\"\n",
    "    elif combined_probability > 0.6:\n",
    "        confidence = \"Medium\"\n",
    "    else:\n",
    "        confidence = \"Low\"\n",
    "\n",
    "    # Extract learning indicators\n",
    "    learning_indicators = []\n",
    "    if features.get('contains_learn', 0):\n",
    "        learning_indicators.append(\"Contains learning keywords\")\n",
    "    if features.get('contains_python', 0):\n",
    "        learning_indicators.append(\"Mentions Python\")\n",
    "    if features.get('contains_basic', 0):\n",
    "        learning_indicators.append(\"Beginners/Basic level\")\n",
    "    if features.get('contains_example', 0):\n",
    "        learning_indicators.append(\"Seeks examples\")\n",
    "\n",
    "    return {\n",
    "        'prediction': final_prediction,\n",
    "        'prediction_label': 'Learning Python' if final_prediction == 1 else 'Not Learning Python',\n",
    "        'confidence': confidence,\n",
    "        'probability': float(combined_probability),\n",
    "        'feature_based_probability': float(probability),\n",
    "        'text_based_probability': float(text_probability),\n",
    "        'learning_indicators': learning_indicators,\n",
    "        'key_features': {k: v for k, v in features.items() if v == 1}\n",
    "    }\n"
   ],
   "id": "abae88094cb5966a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# ## 13. Create API-like Interface\n",
   "id": "cdd1da78655554c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T16:47:53.275455Z",
     "start_time": "2025-12-05T16:47:53.227314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PythonLearningDetector:\n",
    "    \"\"\"\n",
    "    API interface for Python learning preference detection\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the detector with saved models\"\"\"\n",
    "        self.rf_model = joblib.load('python_learning_detector_rf.pkl')\n",
    "        self.rf_text_model = joblib.load('python_learning_detector_text_rf.pkl')\n",
    "        self.vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "        # Load feature names\n",
    "        with open('feature_names.txt', 'r') as f:\n",
    "            self.feature_names = [line.strip() for line in f]\n",
    "\n",
    "    def predict(self, query, code=None):\n",
    "        \"\"\"\n",
    "        Predict if the input indicates Python learning preference\n",
    "\n",
    "        Args:\n",
    "            query (str): User query/question\n",
    "            code (str, optional): Associated code snippet\n",
    "\n",
    "        Returns:\n",
    "            dict: Prediction results\n",
    "        \"\"\"\n",
    "        if code is None:\n",
    "            code = \"\"\n",
    "\n",
    "        # Get prediction\n",
    "        result = predict_python_learning(query, code)\n",
    "\n",
    "        # Add additional analysis\n",
    "        result['query_length'] = len(query)\n",
    "        result['code_length'] = len(code) if code else 0\n",
    "        result['has_code'] = bool(code.strip())\n",
    "\n",
    "        # Categorize query type\n",
    "        if 'how to' in query.lower():\n",
    "            result['query_type'] = 'how-to'\n",
    "        elif 'what is' in query.lower() or 'what are' in query.lower():\n",
    "            result['query_type'] = 'definition'\n",
    "        elif 'example' in query.lower() or 'sample' in query.lower():\n",
    "            result['query_type'] = 'example_request'\n",
    "        elif 'difference' in query.lower() or 'compare' in query.lower():\n",
    "            result['query_type'] = 'comparison'\n",
    "        else:\n",
    "            result['query_type'] = 'general'\n",
    "\n",
    "        return result\n",
    "\n",
    "    def batch_predict(self, queries):\n",
    "        \"\"\"\n",
    "        Predict learning preferences for multiple queries\n",
    "\n",
    "        Args:\n",
    "            queries (list): List of dictionaries with 'query' and optional 'code'\n",
    "\n",
    "        Returns:\n",
    "            list: List of prediction results\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for item in queries:\n",
    "            query = item.get('query', '')\n",
    "            code = item.get('code', None)\n",
    "            results.append(self.predict(query, code))\n",
    "        return results\n",
    "\n",
    "# Example usage\n",
    "print(\"\\nAPI Interface Example:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "detector = PythonLearningDetector()\n",
    "\n",
    "# Single prediction\n",
    "test_query = \"Can you teach me how to write a Python function?\"\n",
    "test_code = \"def add_numbers(a, b):\\n    return a + b\"\n",
    "\n",
    "result = detector.predict(test_query, test_code)\n",
    "print(f\"Query: {test_query}\")\n",
    "print(f\"Prediction: {result['prediction_label']}\")\n",
    "print(f\"Query Type: {result['query_type']}\")\n",
    "print(f\"Confidence: {result['confidence']}\")\n"
   ],
   "id": "8e563c5377a2591f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "API Interface Example:\n",
      "============================================================\n",
      "Query: Can you teach me how to write a Python function?\n",
      "Prediction: Learning Python\n",
      "Query Type: how-to\n",
      "Confidence: Medium\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# ## 14. Model Deployment Recommendations\n",
   "id": "edf392eef9feeae0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"\"\"\n",
    "Model Deployment Recommendations:\n",
    "=================================\n",
    "\n",
    "1. **Integration Options:**\n",
    "   - REST API using Flask/FastAPI\n",
    "   - Streamlit dashboard for visualization\n",
    "   - Browser extension for real-time detection\n",
    "   - IDE plugin for code learning assistance\n",
    "\n",
    "2. **Monitoring:**\n",
    "   - Track prediction accuracy over time\n",
    "   - Monitor feature drift\n",
    "   - Collect user feedback for model improvement\n",
    "\n",
    "3. **Improvement Strategies:**\n",
    "   - Regular retraining with new data\n",
    "   - Active learning from user corrections\n",
    "   - Ensemble with other ML algorithms\n",
    "   - Incorporate user interaction data\n",
    "\n",
    "4. **Use Cases:**\n",
    "   - Personalized learning path recommendations\n",
    "   - Adaptive difficulty adjustment\n",
    "   - Content filtering for learning platforms\n",
    "   - Automated tutoring system triggers\n",
    "\"\"\")\n"
   ],
   "id": "96cdc76529b4d665"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# ## 15. Export Final Analysis Report\n",
   "id": "adae3cdc7fd0693d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T16:47:29.370034Z",
     "start_time": "2025-12-05T16:47:29.363553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create comprehensive analysis report\n",
    "analysis_report = {\n",
    "    'model_performance': {\n",
    "        'accuracy': float(accuracy),\n",
    "        'text_model_accuracy': float(text_accuracy),\n",
    "        'training_samples': len(X_train),\n",
    "        'testing_samples': len(X_test)\n",
    "    },\n",
    "    'feature_analysis': {\n",
    "        'total_features': len(all_feature_columns),\n",
    "        'top_features': feature_importance.head(10)['feature'].tolist(),\n",
    "        'most_important_feature': feature_importance.iloc[0]['feature']\n",
    "    },\n",
    "    'dataset_analysis': {\n",
    "        'total_samples': len(df_processed),\n",
    "        'learning_samples': int(learning_count),\n",
    "        'non_learning_samples': int(total_count - learning_count),\n",
    "        'learning_percentage': float(learning_percentage)\n",
    "    },\n",
    "    'model_configuration': {\n",
    "        'algorithm': 'Random Forest',\n",
    "        'n_estimators': 100,\n",
    "        'max_depth': 10,\n",
    "        'class_weight': 'balanced'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save analysis report\n",
    "import json\n",
    "with open('model_analysis_report.json', 'w') as f:\n",
    "    json.dump(analysis_report, f, indent=2)\n",
    "\n",
    "print(\"Analysis report saved as 'model_analysis_report.json'\")\n",
    "\n",
    "# Display summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL TRAINING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Final Model Accuracy: {accuracy:.2%}\")\n",
    "print(f\"Learning Samples Detected: {learning_count}/{total_count}\")\n",
    "print(f\"Top Feature: {analysis_report['feature_analysis']['most_important_feature']}\")\n",
    "print(\"Models saved: python_learning_detector_rf.pkl\")\n",
    "print(\"Ready for deployment!\")"
   ],
   "id": "a9958695e53c0ae4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis report saved as 'model_analysis_report.json'\n",
      "\n",
      "============================================================\n",
      "MODEL TRAINING COMPLETE\n",
      "============================================================\n",
      "Final Model Accuracy: 86.17%\n",
      "Learning Samples Detected: 7736/13815\n",
      "Top Feature: code_has_function\n",
      "Models saved: python_learning_detector_rf.pkl\n",
      "Ready for deployment!\n"
     ]
    }
   ],
   "execution_count": 60
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
